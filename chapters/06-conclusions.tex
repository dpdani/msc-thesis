\chapter{Conclusions}\label{ch:conclusions}

\section{Future Work}\label{sec:future-work}

Apart from the work already described in Chapter~\ref{ch:design-and-implementation}.

\subsection{\texttt{AtomicDictHandle}}\label{subsec:atomicdicthandle}

A significant portion of the measured time involving \texttt{AtomicDict}'s methods pertains to concurrent reference counting.
Such is because a lot of increments and decrements to the reference count are made when the CPython interpreter executes instructions that involve an instance of \texttt{AtomicDict}.
For instance, every time a lookup, insertion, etc.\ is performed, the Python interpreter increments, and later decrements, the reference count of the involved \texttt{AtomicDict} object.

Considering the necessity to use atomic operations to perform the counting, the amount of time spent in those routines is great ($\sim$15\%--25\% in the benchmarks of Chapter~\ref{ch:measurements}).
Instead of accessing the \texttt{AtomicDict} instance directly, though, it is possible to create a handle for it, like the one described in detail in Appendix~\ref{subsec:atomic-int-handles}.
The handle being a thread-local object, not intended to be shared with other threads, enjoys the fast-path for reference counting, thus reducing the time spent doing reference counting to a negligible amount (that is, close to 0\% of the measured running time following this change).

Since this proposed effort would entail a reduction over the amount of work that needs to be performed by the CPU, especially w.r.t.\ its internal cache coherency protocol, it is expected that an improvement of $\approx$20\% over the measurements of Chapter~\ref{ch:measurements} will be observed.


\subsection{Compatibility with Sub-Interpreters}\label{subsec:compatibility-with-sub-interpreters}

Apart from the aforementioned incompatibility of a stop-the-world GC and lock-freedom discussed in~\S\ref{subsec:garbage-collection}, there is another consequence of using Python objects for the internal data structures of \texttt{AtomicDict}: that it cannot be used with sub-interpreters.
Sub-interpreters are a fairly new technology (dating back to 2017), originally presented in PEP~554~\cite{pep554},\footnote{%
    Later superseded by PEP~734~\cite{pep734}.
} only accessible through C-level APIs.
Creating sub-interpreters from Python code is not yet part of standard CPython distributions.

Historically, since the GIL was deemed an intrinsic presence in the CPython interpreter, there have been various works to circumvent the limitation.
Offloading the parallelizable computation to sub-processes, or custom C extensions are common workarounds to the GIL, as also noted by Gross in PEP~703~\cite{pep703}.
Simplifying a lot of the relevant history, sub-interpreters were also designed with these problems in mind, and were recently enhanced to be endowed with a per-interpreter GIL in PEP~684~\cite{pep684}.
Thus, several threads may have their own GIL, enabling them to run in parallel notwithstanding the continued presence of multiple global interpreter locks:
\begin{quote}
    [\ldots] Multiple interpreter support provide a novel concurrency model focused on isolated threads of execution.
    Furthermore, they provide an opportunity for changes in CPython that will allow simultaneous use of multiple CPU cores (currently prevented by the GIL--see PEP~684).\footnote{See~\cite{pep554}.}
\end{quote}

This, at the expense of not being able to easily share objects between sub-interpreters, as also noted in~\cite[\S~Per-Interpreter GIL]{pep703}.
Inheriting some of their design from Communicating Sequential Processes (CSP), the general idea is that the threads in sub-interpreters exchange information through message-passing, rather than directly sharing memory.
In fact, sharing \emph{objects} between interpreters is not allowed, except for immortal, immutable objects, e.g.\ \texttt{True}, \texttt{None}, etc.

Nonetheless, there are mechanisms to share immutable, and only immutable, data between sub-interpreters.
In~\cite[\S Queue Objects]{pep734} is described a sub-interpreters-compatible implementation of a queue, that can be used to pass \emph{shareable} objects from one interpreter to another.
The list of \emph{shareable} objects is greater than that of immortal, immutable objects.
It also comprises integers, byte arrays, floats, and, among others, a queue instance in itself.
Conceptually, an object qualifies as shareable as long as it can be entirely represented by an immutable array of bytes.\footnote{%
    This is not the actual requirement.
    Instead, there is maintained a list of shareable object types in~\cite[\S Shareable Objects]{pep734}, which can be summarized with this concept.
}

Crucially, a queue is not a Python object.
It is instead allocated and freed without interacting with Python's GC\@.
In order for a queue instance to be supported by sub-interpreters, its internal state cannot be stored into shared objects, because an interpreter accessing the queue would crash when trying to access an object not pertaining to its own object space.
This also entails that there must exist a \texttt{PyObject} \emph{representation} of a queue, which has to be created from the interpreter that desires to access the queue, and no other interpreter.

In fact, a queue can be entirely represented by its ID number.
A queue's memory is entirely allocated outside CPython's object space, and, upon allocation, a new queue is inserted into a shared, global list of queues.
The ID of a queue is its position in the list of queues.
Consequently, for a Python thread to access a queue, it is sufficient to know its ID, to then retrieve the queue from the list.
The object created to interact with a queue from Python code, i.e.\ the \emph{representation} of the queue, only knows the ID of the queue, i.e.\ it just holds an integer; it therefore holds that it can be entirely represented by an array of bytes.
Therefore, a queue can be considered \emph{shareable}, and also be enqueued into another queue, or even into itself.

This \emph{representational} behavior should hold some resemblance to the reader with the \texttt{AtomicDictHandle},\footnote{%
    Described in the above Section.
} whose primary purpose has nothing to do with sub-interpreters, but that can nonetheless be used to hold an immutable, and thus potentially \emph{shareable}, representation of a dictionary.
In fact, it can be entirely represented by an immutable pointer to the \texttt{AtomicDict} instance.
In order for the handle to work properly with sub-interpreters, an additional requirement is that the \texttt{AtomicDict}'s internal data structures should not be Python objects, putting further interest into implementing a different memory management scheme, as already mentioned in~\S\ref{subsec:garbage-collection}.
The instantiation of an \texttt{AtomicDict} would then always necessarily be followed by the instantiation of a handle to it.
Given that the APIs of \texttt{AtomicDict} and \texttt{AtomicDictHandle} are equal by design, there wouldn't be much noticeable difference from the present situation.

Supposing such is performed, more work needs to be carried out in order to ensure that the keys and values in \texttt{AtomicDict} are \emph{shareable}, by also making use of cross-interpreter object representations, in possibly a standardized way, as is the desire in planned work around sub-interpreters.\footnote{%
    During an exchange with Eric Snow, author of the PEPs on sub-interpreters, the necessity for standardized, and customizable ways to create cross-interpreter object representations emerged as one of Snow's planned work.
    A cross-interpreter representation of an object can be thought of as the immutable byte array we have referred to previously.
    Snow's desire is to write a PEP, proposing to create a new \texttt{\_\_xi\_\_} slot (i.e.\ method) for Python classes to return the immutable representation.
}
Or alternatively, by following the current implementation of the interpreters queue.
Such restrictions should also \emph{only} be enforced for these particular use-cases, in order not to impose any restrictions on the keys and values for the use-cases not pertaining to sub-interpreters.

With these enhancements, albeit quite a substantial amount of work to implement them, it becomes entirely possible to make use of the same \texttt{AtomicDict} implementation in both concurrency models: common multi-threading with free-threading, and isolated object spaces multi-threading with sub-interpreters.
